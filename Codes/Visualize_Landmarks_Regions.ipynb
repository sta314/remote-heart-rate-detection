{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './UBFC_DATASET/DATASET_1/'\n",
    "\n",
    "dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "\n",
    "dir_name = dirs[5]\n",
    "vid_folder = os.path.join(root, dir_name)\n",
    "\n",
    "gt_filename = os.path.join(vid_folder, 'gtdump.xmp')\n",
    "if os.path.isfile(gt_filename):\n",
    "    gt_data = np.genfromtxt(gt_filename, delimiter=',')\n",
    "    gt_time = gt_data[:, 0] / 1000\n",
    "    gt_hr = gt_data[:, 1]\n",
    "    gt_trace = gt_data[:, 3]\n",
    "else:\n",
    "    gt_filename = os.path.join(vid_folder, 'ground_truth.txt')\n",
    "    if os.path.isfile(gt_filename):\n",
    "        gt_data = np.loadtxt(gt_filename,)\n",
    "        gt_trace = gt_data[0,:]\n",
    "        gt_hr = gt_data[1,:]\n",
    "        gt_time = gt_data[2,:]\n",
    "\n",
    "gt_trace = (gt_trace - np.mean(gt_trace)) / np.std(gt_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name: 7-gt\n",
      "vid_folder: ./UBFC_DATASET/DATASET_1/7-gt\n",
      "gt_trace shape: (5128,)\n",
      "gt_hr shape: (5128,)\n",
      "gt_time shape: (5128,)\n"
     ]
    }
   ],
   "source": [
    "print(\"dir_name:\", dir_name)\n",
    "print(\"vid_folder:\", vid_folder)\n",
    "print(\"gt_trace shape:\", gt_trace.shape)\n",
    "print(\"gt_hr shape:\", gt_hr.shape)\n",
    "print(\"gt_time shape:\", gt_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "vid_path = os.path.join(vid_folder, 'vid.avi')\n",
    "vidObj = cv2.VideoCapture(vid_path)\n",
    "face_list = []\n",
    "\n",
    "fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "first_frame = True\n",
    "tracker = dlib.correlation_tracker()\n",
    "\n",
    "# Load the face detector and the shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_81_face_landmarks.dat\")\n",
    "\n",
    "# Function to extract facial landmarks\n",
    "def extract_facial_landmarks(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    landmarks = []\n",
    "    for face in faces:\n",
    "        shape = predictor(gray, face)\n",
    "        for i in range(81):\n",
    "            x = shape.part(i).x\n",
    "            y = shape.part(i).y\n",
    "            landmarks.append((x, y))\n",
    "    return landmarks\n",
    "\n",
    "# Def visualize points poly\n",
    "def visualize_points_poly(frame, points, color, alpha=0.3):\n",
    "    overlay = frame.copy()\n",
    "    cv2.fillPoly(overlay, points, color)\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    for i in range(0, len(points) - 1):\n",
    "        cv2.line(frame, points[i], points[i+1], color, 1)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open the video file\n",
    "vidObj = cv2.VideoCapture(vid_path)\n",
    "\n",
    "# Create a VideoWriter object to save the output video\n",
    "output_path = os.path.join(vid_folder, 'output.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (int(vidObj.get(3)), int(vidObj.get(4))))\n",
    "\n",
    "# Process each frame of the video\n",
    "while True:\n",
    "    ret, frame = vidObj.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    landmarks = extract_facial_landmarks(frame)\n",
    "    \n",
    "    # Draw landmarks on the frame\n",
    "    for i, landmark in enumerate(landmarks):\n",
    "        cv2.circle(frame, landmark, 1, (0, 0, 0), -1)\n",
    "\n",
    "    frame = visualize_points_poly(frame, [np.array(landmarks)[[4, 29, 1]]], (255, 0, 0))\n",
    "    frame = visualize_points_poly(frame, [np.array(landmarks)[[29, 12, 15]]], (0, 255, 0))\n",
    "    frame = visualize_points_poly(frame, [np.array(landmarks)[[19, 24, 72, 69]]], (0, 0, 255))\n",
    "    frame = visualize_points_poly(frame, [np.array(landmarks)[[8, 12, 57, 4]]], (255, 255, 0))\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    output.write(frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Facial Landmarks', frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video objects\n",
    "vidObj.release()\n",
    "output.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
